{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3f5ca03fe6414ca85c6123ed3394c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22265e0a7074fc6ac1a1489d03dd238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764234b7b34b43218336c08c45f8dcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "        keyword_1 keyword_2 keyword_3 keyword_4  keyword_5  keyword_6  \\\n",
      "topic_0      year       sex       set   tuesday  taskforce     police   \n",
      "topic_1      body    worker       set    police  kimberley  taskforce   \n",
      "topic_2       set    police    worker   tuesday  taskforce        sex   \n",
      "topic_3       set    police    worker   tuesday  taskforce        sex   \n",
      "topic_4       set    police    worker   tuesday  taskforce        sex   \n",
      "\n",
      "           keyword_7 keyword_8    keyword_9 keyword_10  \n",
      "topic_0       coogee     death  investigate      mcrae  \n",
      "topic_1  investigate     death       coogee      mcrae  \n",
      "topic_2         body     death    kimberley     coogee  \n",
      "topic_3         body     death    kimberley     coogee  \n",
      "topic_4         body     death    kimberley     coogee  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e3310301cc43d1bf534856d580d1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "from string import punctuation\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "pickle_in = open(\"data-model/scrapped_df_other.pkl\",\"rb\") \n",
    "data = pickle.load(pickle_in) \n",
    "\n",
    "data = data.drop_duplicates('description')\n",
    "data = data[~data['description'].isnull()]\n",
    "data = data[(data.description.map(len) > 140) & (data.description.map(len) <= 300)]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "f = open('./data-model/stopwords.txt', 'r')\n",
    "for l in f.readlines():\n",
    "    stop_words.append(l.replace('\\n', ''))\n",
    "    \n",
    "additional_stop_words = ['t', 'will']\n",
    "stop_words += additional_stop_words\n",
    "\n",
    "def reduce(function, iterable, initializer=None):\n",
    "    it = iter(iterable)\n",
    "    if initializer is None:\n",
    "        value = next(it)\n",
    "    else:\n",
    "        value = initializer\n",
    "    for element in it:\n",
    "        value = function(value, element)\n",
    "    return value\n",
    "\n",
    "def _removeNonAscii(s): \n",
    "    return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = text.replace('(ap)', '')\n",
    "    text = re.sub(r\"\\'s\", \" is \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r\"\\\\\", \"\", text)\n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)\n",
    "    text = re.sub('[^a-zA-Z ?!]+', '', text)\n",
    "    text = _removeNonAscii(text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = clean_text(text)    \n",
    "    tokens = [word_tokenize(sent) for sent in sent_tokenize(text)]\n",
    "    tokens = list(reduce(lambda x,y: x+y, tokens))\n",
    "    tokens = list(filter(lambda token: token not in (stop_words + list(punctuation)) , tokens))\n",
    "    return tokens\n",
    "\n",
    "data = data.loc[[0]]\n",
    "\n",
    "data['description'] = data['description'].map(lambda d: str(d))\n",
    "data['tokens'] = data['description'].progress_map(lambda d: tokenizer(d))\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim import matutils\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "aux = data.copy()\n",
    "\n",
    "bigram = gensim.models.Phrases(aux['tokens'], min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "aux['tokens_bigram'] = aux['tokens'].progress_map(lambda tokens: bigram_mod[tokens])\n",
    "\n",
    "id2word = corpora.Dictionary(aux['tokens_bigram'])\n",
    "texts = aux['tokens_bigram'].values\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]    \n",
    "\n",
    "def LDA_model(num_topics, passes=1):\n",
    "    return gensim.models.ldamodel.LdaModel(corpus=tqdm_notebook(corpus, leave=False),\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=num_topics, \n",
    "                                               random_state=100,\n",
    "                                               eval_every=10,\n",
    "                                               chunksize=2000,\n",
    "                                               passes=passes,\n",
    "                                               per_word_topics=True\n",
    "                                            )\n",
    "\n",
    "def compute_coherence(model):\n",
    "    coherence = CoherenceModel(model=model, \n",
    "                           texts=aux['tokens_bigram'].values,\n",
    "                           dictionary=id2word, coherence='c_v')\n",
    "    return coherence.get_coherence()\n",
    "\n",
    "def display_topics(model):\n",
    "    topics = model.show_topics(num_topics=model.num_topics, formatted=False, num_words=10)\n",
    "    topics = map(lambda c: map(lambda cc: cc[0], c[1]), topics)\n",
    "    df = pd.DataFrame(topics)\n",
    "    df.index = ['topic_{0}'.format(i) for i in range(model.num_topics)]\n",
    "    df.columns = ['keyword_{0}'.format(i) for i in range(1, 10+1)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def explore_models(df, rg=range(5, 25)):\n",
    "    models = []\n",
    "    coherences = []\n",
    "    \n",
    "    for num_topics in tqdm_notebook(rg, leave=False):\n",
    "        lda_model = LDA_model(num_topics, passes=5)\n",
    "        models.append(lda_model)\n",
    "        coherence = compute_coherence(lda_model)\n",
    "        coherences.append(coherence)\n",
    "    \n",
    "    return coherences, models\n",
    "\n",
    "coherences, models = explore_models(aux, rg=range(5, 85, 5))\n",
    "\n",
    "best_model = LDA_model(num_topics=5, passes=50)\n",
    "\n",
    "print(display_topics(model=best_model))\n",
    "\n",
    "def get_document_topic_matrix(corpus, num_topics=best_model.num_topics):\n",
    "    matrix = []\n",
    "    for row in tqdm_notebook(corpus):\n",
    "        output = np.zeros(num_topics)\n",
    "        doc_proba = best_model[row][0]\n",
    "        for doc, proba in doc_proba:\n",
    "            output[doc] = proba\n",
    "        matrix.append(output)\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix\n",
    "\n",
    "matrix = get_document_topic_matrix(corpus)\n",
    "\n",
    "doc_topic = best_model.get_document_topics(corpus)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
